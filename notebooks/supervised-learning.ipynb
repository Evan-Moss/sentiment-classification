{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Notebook to explore the pre-processing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adelliinaa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adelliinaa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/adelliinaa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import nltk # To download\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') # For stop words\n",
    "nltk.download('wordnet') # For POS \n",
    "nltk.download('averaged_perceptron_tagger') # For POS tagging\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/stanfordSentimentTreebank/dictionary.txt', sep='|', index_col=1)\n",
    "train_test = pd.read_csv('../data/stanfordSentimentTreebank/sentiment_labels.txt', sep='|', index_col=0)\n",
    "\n",
    "#data.rename(columns={0: 'phrase_ids', 1: 'phrase'})\n",
    "data.columns = ['phrase_tokens']\n",
    "data.index.names = ['phrase_id']\n",
    "train_test.columns = ['sentiment_value']\n",
    "train_test.index.names = ['phrase_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def get_pos_from_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "    \n",
    "def pre_processing(collection):\n",
    "    # Case-fold\n",
    "    collection = collection.lower()\n",
    "    \n",
    "    # Tokenising, converts all non-chars, new-lines and tabs to ' '\n",
    "    collection = list(filter(None, re.sub(r'[\\W]', ' ',collection).split(' ')))\n",
    "    collection = pos_tag(collection)\n",
    "    \n",
    "    # Stemming and Stopping \n",
    "    return [lemmatizer.lemmatize(term[0], pos = get_pos_from_tag(term[1])) for term in collection if term[0] not in stop_words] \n",
    "\n",
    "#pre_processing(\"This is a test sentence I love this film it's good. better than the last one, greater than the second one it was playing plays played\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre_processing to data\n",
    "\n",
    "data['phrase_tokens'] = data['phrase_tokens'].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty phrases \n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if len(row[0]) == 0:\n",
    "        data = data.drop([index], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Join on phrase_id\n",
    "\n",
    "labelled_phrases = pd.merge(data, train_test, left_index=True, right_index=True)\n",
    "labelled_phrases = labelled_phrases.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#UNCOMMENT FOR BINARY CLASIFICATION\n",
    "conditions = [\n",
    "    (labelled_phrases['sentiment_value'] >= 0) & (labelled_phrases['sentiment_value'] <= 0.55),\n",
    "    (labelled_phrases['sentiment_value'] > 0.55) & (labelled_phrases['sentiment_value'] <= 1)]\n",
    "values = ['negative', 'positive']\n",
    "labelled_phrases['sentiment'] = np.select(conditions, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (labelled_phrases['sentiment_value'] >= 0) & (labelled_phrases['sentiment_value'] <= 0.2),\n",
    "    (labelled_phrases['sentiment_value'] > 0.2) & (labelled_phrases['sentiment_value'] <= 0.4),\n",
    "    (labelled_phrases['sentiment_value'] > 0.4) & (labelled_phrases['sentiment_value'] <= 0.6),\n",
    "    (labelled_phrases['sentiment_value'] > 0.6) & (labelled_phrases['sentiment_value'] <= 0.8),\n",
    "    (labelled_phrases['sentiment_value'] > 0.8) & (labelled_phrases['sentiment_value'] <= 1)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['very_negative', 'negative', 'neutral', 'positive', 'very_positive']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "labelled_phrases['sentiment'] = np.select(conditions, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokens</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phrase_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cockettes]</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cockettes]</td>\n",
       "      <td>0.42708</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[cockettes, provide, window, subculture, hell,...</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[cockettes, provide, window, subculture, hell,...</td>\n",
       "      <td>0.41667</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[cockettes, provide, window, subculture, hell,...</td>\n",
       "      <td>0.54167</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               phrase_tokens  sentiment_value  \\\n",
       "phrase_id                                                                       \n",
       "3                                                [cockettes]          0.50000   \n",
       "4                                                [cockettes]          0.42708   \n",
       "5          [cockettes, provide, window, subculture, hell,...          0.37500   \n",
       "6          [cockettes, provide, window, subculture, hell,...          0.41667   \n",
       "7          [cockettes, provide, window, subculture, hell,...          0.54167   \n",
       "\n",
       "          sentiment  \n",
       "phrase_id            \n",
       "3           neutral  \n",
       "4           neutral  \n",
       "5          negative  \n",
       "6           neutral  \n",
       "7           neutral  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_phrases.to_csv('labelled_phrases.csv', index=True)\n",
    "labelled_phrases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Label')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = labelled_phrases[\"sentiment\"].value_counts(sort=False).plot(kind=\"barh\")\n",
    "ax.set_xlabel(\"Number of Samples in training Set\")\n",
    "ax.set_ylabel(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labelled_phrases.csv')\n",
    "data = data.drop(columns=['phrase_id', 'sentiment_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cockettes']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['cockettes']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cockettes', 'provide', 'window', 'subculture...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cockettes', 'provide', 'window', 'subculture...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cockettes', 'provide', 'window', 'subculture...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237439</th>\n",
       "      <td>['standard', 'hollywood', 'bio', 'pic']</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237440</th>\n",
       "      <td>['typical', 'fish', 'water', 'story']</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237441</th>\n",
       "      <td>['zero']</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237442</th>\n",
       "      <td>['zippy', 'jazzy', 'score']</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237443</th>\n",
       "      <td>['unk']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237444 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            phrase_tokens      sentiment\n",
       "0                                           ['cockettes']        neutral\n",
       "1                                           ['cockettes']        neutral\n",
       "2       ['cockettes', 'provide', 'window', 'subculture...       negative\n",
       "3       ['cockettes', 'provide', 'window', 'subculture...        neutral\n",
       "4       ['cockettes', 'provide', 'window', 'subculture...        neutral\n",
       "...                                                   ...            ...\n",
       "237439            ['standard', 'hollywood', 'bio', 'pic']       negative\n",
       "237440              ['typical', 'fish', 'water', 'story']       negative\n",
       "237441                                           ['zero']       negative\n",
       "237442                        ['zippy', 'jazzy', 'score']  very_positive\n",
       "237443                                            ['unk']        neutral\n",
       "\n",
       "[237444 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = np.array(data['phrase_tokens'])\n",
    "sentiments = np.array(data['sentiment'])\n",
    "\n",
    "# build train and test datasets\n",
    "train_reviews, test_reviews, train_sentiments, test_sentiments = train_test_split(reviews, sentiments , test_size=0.20,  random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.8.0.post1-py3-none-any.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.20.0 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (1.19.5)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.tar.gz (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (3.3.4)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Collecting hyperopt>=0.1.1\n",
      "  Downloading hyperopt-0.2.5-py2.py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (4.47.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (2.8.1)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting janome\n",
      "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "\u001b[K     |████████████████████████████████| 788 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (2020.6.8)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: lxml in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (4.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (0.24.1)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from flair) (3.8.3)\n",
      "Collecting transformers>=4.0.0\n",
      "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gdown==3.12.2\n",
      "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch<=1.7.1,>=1.5.0\n",
      "  Downloading torch-1.7.1-cp38-none-macosx_10_9_x86_64.whl (108.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 108.9 MB 259 kB/s eta 0:00:01    |███████████████▏                | 51.4 MB 3.0 MB/s eta 0:00:20\n",
      "\u001b[?25hCollecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 923 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (7.2.0)\n",
      "Requirement already satisfied: requests in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from huggingface-hub->flair) (2.25.1)\n",
      "Requirement already satisfied: filelock in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from huggingface-hub->flair) (3.0.12)\n",
      "Requirement already satisfied: scipy in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
      "Requirement already satisfied: future in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: cloudpickle in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: six in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair) (1.15.0)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from gensim<=3.8.3,>=3.4.0->flair) (3.0.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.2-cp38-cp38-macosx_10_11_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from transformers>=4.0.0->flair) (20.4)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.44.tar.gz (862 kB)\n",
      "\u001b[K     |████████████████████████████████| 862 kB 639 kB/s eta 0:00:01     |████████████████▍               | 440 kB 543 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub->flair) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub->flair) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub->flair) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub->flair) (4.0.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
      "Requirement already satisfied: click in /Users/adelliinaa/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
      "Building wheels for collected packages: ftfy, mpld3, segtok, gdown, langdetect, sqlitedict, overrides, sacremoses\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0-py3-none-any.whl size=41620 sha256=9446f957770822e218771d51a59a871d2339c769ff2e09d28c86483000046850\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/6e/94/84/52f0523a13dc8c2d5bd2b744386f91e134c5efb2b86998bbc2\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=a3a26837ace7c6542283321d6567b7cc4603edf4b8f6efe79d6981c84a9133ab\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/3d/9f/9d/d806a20bd97bc7076d724fa3e69fa5be61836ba16b2ffa6126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25018 sha256=40b65953834d7746be1885f0575007f0b0898c92c5b4bbeb213d3664b5528b0e\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/36/6d/90/6d9b11ba404f68f340ef3f6060cfdf9c9f34653b08eceeacf6\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9681 sha256=00a2bdd1c8699618275c546d850028ac4af0b62bacd13cc68572e5417c6337c8\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/e2/62/1e/926d1ebe7b1e733c78d627fd288d01b83feaf67efc06e0e4c3\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993190 sha256=9c86cb2634b380723bd0a3da4c2ce64184074b48e863686174d1d0ed024a47ea\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/1e/80/23/0a24928ec3a3906ff5027f38d2fea824e7e97f2ba7c83d91e3\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14376 sha256=ba70398db1ce3805e420020005ac7cc57ced9cc1411dcde9dae9c63fb65c1647\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/92/82/8c/54ef8d8770fd1a80938197e55d3ccd26eccd117f44c58f601b\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10175 sha256=7193ef8b8d5e6d60f557b290a1e9eb98e139f117af1a5bca6b7e2e18241f3708\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/6a/4f/72/28857f75625b263e2e3f5ab2fc4416c0a85960ac6485007eaa\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.44-py3-none-any.whl size=886084 sha256=eba146b40b87006fef008d4f8ce4cde1c3380b07324f9a64d062b3ef28061312\n",
      "  Stored in directory: /Users/adelliinaa/Library/Caches/pip/wheels/d6/17/75/f2ed13c472c4cecc14f003401bb45efadca64cc589d4bf3103\n",
      "Successfully built ftfy mpld3 segtok gdown langdetect sqlitedict overrides sacremoses\n",
      "Installing collected packages: ftfy, huggingface-hub, hyperopt, tabulate, sentencepiece, janome, mpld3, segtok, overrides, importlib-metadata, konoha, bpemb, tokenizers, sacremoses, transformers, gdown, torch, deprecated, langdetect, sqlitedict, flair\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0 gdown-3.12.2 huggingface-hub-0.0.8 hyperopt-0.2.5 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.4 langdetect-1.0.8 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.44 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tabulate-0.8.9 tokenizers-0.10.2 torch-1.7.1 transformers-4.5.1\n",
      "2021-04-13 20:14:00,153 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-jw300-forward-v0.1.pt not found in cache, downloading to /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmpekb2gwy_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172513724/172513724 [06:04<00:00, 472898.74B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:20:05,149 copying /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmpekb2gwy_ to cache at /Users/adelliinaa/.flair/embeddings/lm-jw300-forward-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:20:05,344 removing temp file /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmpekb2gwy_\n",
      "2021-04-13 20:20:06,176 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-jw300-backward-v0.1.pt not found in cache, downloading to /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmpaz3ait_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172513724/172513724 [08:16<00:00, 347407.37B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:28:22,960 copying /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmpaz3ait_y to cache at /Users/adelliinaa/.flair/embeddings/lm-jw300-backward-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:28:23,058 removing temp file /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmpaz3ait_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-33aa0f2a0b37>:10: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
      "  optional_embedding = BertEmbeddings('bert-base-cased')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae10a973a00646ea98b31c86fa13dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391393d2f6254207b64b6e38966c7f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2c8a00769a4cf785294494b85319be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36839228a6b40a78f26542e9c33e78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7277abb7a44da59f38d7ca59bb80ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-04-13 20:40:55,183 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmp024fzbqr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034624/73034624 [00:31<00:00, 2314710.91B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:41:26,976 copying /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmp024fzbqr to cache at /Users/adelliinaa/.flair/embeddings/news-forward-0.4.1.pt\n",
      "2021-04-13 20:41:27,011 removing temp file /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmp024fzbqr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:41:27,359 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmp2znxdhca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034575/73034575 [00:29<00:00, 2502368.00B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:41:56,800 copying /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmp2znxdhca to cache at /Users/adelliinaa/.flair/embeddings/news-backward-0.4.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 20:41:56,836 removing temp file /var/folders/pq/t04fqz7n1c96gclr_9nxrz900000gn/T/tmp2znxdhca\n"
     ]
    }
   ],
   "source": [
    "!pip install flair\n",
    "\n",
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings, WordEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "# init Flair embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "\n",
    "# init BERT base (cases)\n",
    "optional_embedding = BertEmbeddings('bert-base-cased')\n",
    "# OR init ELMo (original)\n",
    "# optional_embedding = ELMoEmbeddings('original')\n",
    "\n",
    "word_embeddings = list(filter(None, [\n",
    "    optional_embedding,\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward'),\n",
    "]))\n",
    "\n",
    "# Initialize document embedding by passing list of word embeddings\n",
    "document_embeddings = DocumentRNNEmbeddings(\n",
    "    word_embeddings,\n",
    "    hidden_size=512,\n",
    "    reproject_words=True,\n",
    "    reproject_words_dimension=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    \"\"\"Base class that houses common utilities for reading in test data\n",
    "    and calculating model accuracy and F1 scores.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def read_data(self, fname: str, lower_case: bool=False,\n",
    "                  colnames=['sentiment', 'text']) -> pd.DataFrame:\n",
    "        \"Read in test data into a Pandas DataFrame\"\n",
    "        df = pd.read_csv(fname, sep='\\t', header=None, names=colnames)\n",
    "        df['sentiment'] = df['sentiment'].str.replace('__label__', '')\n",
    "        # Categorical data type for truth labels\n",
    "        df['sentiment'] = df['sentiment'].astype(int).astype('category')\n",
    "        # Optional lowercase for test data (if model was trained on lowercased text)\n",
    "        if lower_case:\n",
    "            df['text'] = df['text'].str.lower()\n",
    "        return df\n",
    "\n",
    "    def accuracy(self, df: pd.DataFrame) -> None:\n",
    "        \"Prediction accuracy (percentage) and F1 score\"\n",
    "        acc = accuracy_score(df['truth'], df['pred'])*100\n",
    "        f1 = f1_score(df['truth'], df['pred'], average='macro')\n",
    "        print(\"Accuracy: {}\\nMacro F1-score: {}\".format(acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlairSentiment(Base):\n",
    "    \"\"\"Predict fine-grained sentiment scores using Flair.\"\"\"\n",
    "    def __init__(self, model_file: str=None) -> None:\n",
    "        super().__init__()\n",
    "        from flair.models import TextClassifier\n",
    "        self.model = TextClassifier.load(model_file)\n",
    "\n",
    "    def score(self, text: str) -> int:\n",
    "        from flair.data import Sentence\n",
    "        doc = Sentence(text)\n",
    "        self.model.predict(doc)\n",
    "        pred = int(doc.labels[0].value)\n",
    "        return pred\n",
    "\n",
    "    def predict(self, train_file: None, test_file: str, lower_case: bool) -> pd.DataFrame:\n",
    "        \"Use tqdm to display model prediction status bar\"\n",
    "        from tqdm import tqdm\n",
    "        tqdm.pandas()\n",
    "        df = self.read_data(test_file, lower_case)\n",
    "        df['pred'] = df['text'].progress_apply(self.score)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (189955, 105660)  Test features shape: (47489, 105660)\n",
      "TFIDF model:> Train features shape: (189955, 105660)  Test features shape: (47489, 105660)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(train_reviews)\n",
    "\n",
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(train_reviews)\n",
    "\n",
    "\n",
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(test_reviews)\n",
    "tv_test_features = tv.transform(test_reviews)\n",
    "\n",
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "svm = SGDClassifier(loss='hinge', l1_ratio=0.15, max_iter=1000, n_jobs=4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_report(true_labels, predicted_labels, target_names):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels, y_pred=predicted_labels, target_names=target_names) \n",
    "    print(report)\n",
    "    \n",
    "def display_model_performance_metrics(true_labels, predicted_labels, target_names):\n",
    "    print('Model Performance metrics:')\n",
    "    print('-'*30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('-'*30)\n",
    "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, target_names=target_names)\n",
    "    print('\\nPrediction Confusion Matrix:')\n",
    "    print('-'*30)\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    print('Accuracy:  {:2.2%} '.format(metrics.accuracy_score(true_labels, predicted_labels)))\n",
    "    print('Precision: {:2.2%} '.format(metrics.precision_score(true_labels, predicted_labels, average='weighted')))\n",
    "    print('Recall:    {:2.2%} '.format(metrics.recall_score(true_labels, predicted_labels, average='weighted')))\n",
    "    print('F1 Score:  {:2.2%} '.format(metrics.f1_score(true_labels, predicted_labels, average='weighted')))\n",
    "         \n",
    "        \n",
    "def display_model_performance_metrics(true_labels, predicted_labels, target_names):\n",
    "    print('Model Performance metrics:')\n",
    "    print('-'*30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('-'*30)\n",
    "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, target_names=target_names)\n",
    "\n",
    "\n",
    "def train_predict_model(classifier,  train_features, train_labels,  test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    return predictions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelliinaa/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy:  65.78% \n",
      "Precision: 64.47% \n",
      "Recall:    65.78% \n",
      "F1 Score:  64.45% \n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "very_negative       0.58      0.46      0.52      8592\n",
      "     negative       0.71      0.85      0.77     23569\n",
      "      neutral       0.60      0.51      0.55     10023\n",
      "     positive       0.52      0.35      0.42      2252\n",
      "very_positive       0.59      0.42      0.49      3053\n",
      "\n",
      "     accuracy                           0.66     47489\n",
      "    macro avg       0.60      0.52      0.55     47489\n",
      " weighted avg       0.64      0.66      0.64     47489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on BOW features\n",
    "lr_bow_predictions = train_predict_model(classifier=lr, \n",
    "                                         train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                         test_features=cv_test_features, test_labels=test_sentiments)\n",
    "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\n",
    "                                  target_names=['very_negative', 'negative', 'neutral', 'positive', 'very_positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelliinaa/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy:  64.97% \n",
      "Precision: 63.58% \n",
      "Recall:    64.97% \n",
      "F1 Score:  63.50% \n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 5, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-bdbc5fdfb12e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          \u001b[0mtrain_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_train_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m37000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m37000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          test_features=cv_test_features[-37000:], test_labels=test_sentiments[-37000:])\n\u001b[0;32m----> 6\u001b[0;31m display_model_performance_metrics(true_labels=test_sentiments[-37000:], predicted_labels=lr_bow_predictions,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                   target_names=['negative', 'positive'])\n",
      "\u001b[0;32m<ipython-input-74-01e842fc850a>\u001b[0m in \u001b[0;36mdisplay_model_performance_metrics\u001b[0;34m(true_labels, predicted_labels, target_names)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nModel Classification report:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdisplay_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-01e842fc850a>\u001b[0m in \u001b[0;36mdisplay_classification_report\u001b[0;34m(true_labels, predicted_labels, target_names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1985\u001b[0m             )\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1988\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 5, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# RESULTS FOR BINARY CLASSIFICATION\n",
    "# Logistic Regression model on BOW features\n",
    "lr_bow_predictions = train_predict_model(classifier=lr, \n",
    "                                         train_features=cv_train_features[:-37000], train_labels=train_sentiments[:-37000],\n",
    "                                         test_features=cv_test_features[-37000:], test_labels=test_sentiments[-37000:])\n",
    "display_model_performance_metrics(true_labels=test_sentiments[-37000:], predicted_labels=lr_bow_predictions,\n",
    "                                  target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM results with Bow:\n",
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy:  61.70% \n",
      "Precision: 60.44% \n",
      "Recall:    61.70% \n",
      "F1 Score:  58.20% \n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "very_negative       0.57      0.30      0.39      6677\n",
      "     negative       0.63      0.91      0.75     18326\n",
      "      neutral       0.59      0.36      0.44      7804\n",
      "     positive       0.54      0.29      0.38      1777\n",
      "very_positive       0.59      0.38      0.46      2416\n",
      "\n",
      "     accuracy                           0.62     37000\n",
      "    macro avg       0.58      0.45      0.48     37000\n",
      " weighted avg       0.60      0.62      0.58     37000\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "SVM results with TF-IDF:\n",
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy:  52.69% \n",
      "Precision: 53.38% \n",
      "Recall:    52.69% \n",
      "F1 Score:  41.94% \n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "very_negative       0.53      0.07      0.12      6677\n",
      "     negative       0.53      0.96      0.68     18326\n",
      "      neutral       0.51      0.12      0.19      7804\n",
      "     positive       0.61      0.08      0.13      1777\n",
      "very_positive       0.62      0.13      0.22      2416\n",
      "\n",
      "     accuracy                           0.53     37000\n",
      "    macro avg       0.56      0.27      0.27     37000\n",
      " weighted avg       0.53      0.53      0.42     37000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = train_predict_model(classifier=svm, \n",
    "                                          train_features=cv_train_features[:-37000], train_labels=train_sentiments[:-37000],\n",
    "                                          test_features=cv_test_features[-37000:], test_labels=test_sentiments[-37000:])\n",
    "print('SVM results with Bow:')\n",
    "display_model_performance_metrics(true_labels=test_sentiments[-37000:], predicted_labels=svm_bow_predictions,\n",
    "                                 target_names=['very_negative', 'negative', 'neutral', 'positive', 'very_positive'])\n",
    "\n",
    "\n",
    "svm_tfidf_predictions = train_predict_model(classifier=svm, \n",
    "                                            train_features=tv_train_features[:-37000], train_labels=train_sentiments[:-37000],\n",
    "                                            test_features=tv_test_features[-37000:], test_labels=test_sentiments[-37000:])\n",
    "print('-'*60)\n",
    "print('\\nSVM results with TF-IDF:')\n",
    "display_model_performance_metrics(true_labels=test_sentiments[-37000:], predicted_labels=svm_tfidf_predictions,\n",
    "                                  target_names=['very_negative', 'negative', 'neutral', 'positive', 'very_positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM results with Bow:\n",
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy:  80.56% \n",
      "Precision: 81.36% \n",
      "Recall:    80.56% \n",
      "F1 Score:  79.47% \n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.94      0.86     30021\n",
      "    positive       0.85      0.57      0.68     17468\n",
      "\n",
      "    accuracy                           0.81     47489\n",
      "   macro avg       0.82      0.76      0.77     47489\n",
      "weighted avg       0.81      0.81      0.79     47489\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "SVM results with TF-IDF:\n",
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy:  73.44% \n",
      "Precision: 77.15% \n",
      "Recall:    73.44% \n",
      "F1 Score:  69.43% \n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.97      0.82     30021\n",
      "    positive       0.87      0.33      0.47     17468\n",
      "\n",
      "    accuracy                           0.73     47489\n",
      "   macro avg       0.79      0.65      0.65     47489\n",
      "weighted avg       0.77      0.73      0.69     47489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = train_predict_model(classifier=svm, \n",
    "                                          train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                          test_features=cv_test_features, test_labels=test_sentiments)\n",
    "print('SVM results with Bow:')\n",
    "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_bow_predictions,\n",
    "                                 target_names=['negative', 'positive'])\n",
    "\n",
    "\n",
    "svm_tfidf_predictions = train_predict_model(classifier=svm, \n",
    "                                            train_features=tv_train_features, train_labels=train_sentiments,\n",
    "                                            test_features=tv_test_features, test_labels=test_sentiments)\n",
    "print('-'*60)\n",
    "print('\\nSVM results with TF-IDF:')\n",
    "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_tfidf_predictions,\n",
    "                                  target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
